{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25e08c21-2059-41c2-8c4d-90686d8f4ca1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "f10e0756-975b-4e33-9ff5-ccaa92435596"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import math\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "2090da17-3cbe-4551-9104-73e02ae1f7d4"
      },
      "outputs": [],
      "source": [
        "class Parameter:\n",
        "    def __init__(self, value: float, name: str, _children = ()) -> None:\n",
        "        self._value = value\n",
        "        self._name = name\n",
        "\n",
        "        self._grad = 0.0\n",
        "        self._backward = lambda: None\n",
        "\n",
        "        self._prev = set(_children)\n",
        "\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f\"Parameter {self._name} = {self._value}; dL/d[{self._name}] = {self._grad}\"\n",
        "\n",
        "\n",
        "    def __pow__(self, other):\n",
        "      assert isinstance(other, (int, float)), \"only supporting int/float powers for now\"\n",
        "      out = Parameter(\n",
        "          self._value**other,\n",
        "          f'**{other}',\n",
        "          (self,)\n",
        "      )\n",
        "\n",
        "      def _backward():\n",
        "          self._grad += other * (self._value ** (other - 1)) * out._grad\n",
        "      out._backward = _backward\n",
        "\n",
        "      return out\n",
        "\n",
        "\n",
        "    def __mul__(self, other):\n",
        "      other = other if isinstance(other, Parameter) else Parameter(other, '')\n",
        "      out = Parameter(\n",
        "          self._value * other._value,\n",
        "          f'{self._name} * {other._name}',\n",
        "          (self, other)\n",
        "      )\n",
        "\n",
        "      def _backward():\n",
        "        self._grad += out._grad * other._value  # dL / dself\n",
        "        other._grad += out._grad * self._value  # dL / dother\n",
        "      out._backward = _backward\n",
        "\n",
        "      return out\n",
        "\n",
        "\n",
        "    def __add__(self, other):\n",
        "      other = other if isinstance(other, Parameter) else Parameter(other, '')\n",
        "      out = Parameter (\n",
        "          self._value + other._value,\n",
        "          f'[{self._name} + {other._name}]',\n",
        "          (self, other)\n",
        "      )\n",
        "\n",
        "      def _backward():\n",
        "        self._grad += 1.0 * out._grad   # dL / dself\n",
        "        other._grad += 1.0 * out._grad  # dL / dother\n",
        "      out._backward = _backward\n",
        "\n",
        "      return out\n",
        "\n",
        "\n",
        "    def __neg__(self): # -self\n",
        "      return self * (-1)\n",
        "\n",
        "    def __sub__(self, other):  # self - other\n",
        "      other = other if isinstance(other, Parameter) else Parameter(other, '')\n",
        "      return self + (-other)\n",
        "\n",
        "\n",
        "\n",
        "    def sigmoid(self):\n",
        "        # f(x) = 1 / (1 + exp(-self._value))\n",
        "        # f'(x) = f(x) * (1 - f(x))\n",
        "\n",
        "        val = 1.0 / (1.0 + math.exp(-self._value))\n",
        "\n",
        "        result = Parameter(\n",
        "            val,\n",
        "             f\"Ïƒ({self._name})\",\n",
        "            (self, )\n",
        "        )\n",
        "\n",
        "        def _backward():\n",
        "            self._grad += result._grad * val * (1 - val)\n",
        "\n",
        "        result._backward = _backward\n",
        "\n",
        "        return result\n",
        "\n",
        "\n",
        "    def silu(self):\n",
        "        # silu(x) = self._value * sigmoid(self._value)\n",
        "        # silu'(x) = sigmoid(self._value) * (1.0 + self._value - silu(self._value))\n",
        "\n",
        "        sigmoid = self.sigmoid()._value\n",
        "        val = self._value * sigmoid\n",
        "\n",
        "        result = Parameter (\n",
        "            val,\n",
        "            f\"SiLU({self._name})\",\n",
        "            (self, )\n",
        "        )\n",
        "\n",
        "        def _backward():\n",
        "            self._grad += result._grad * (sigmoid * (1.0 + self._value - val))\n",
        "\n",
        "        result._backward = _backward\n",
        "\n",
        "        return result\n",
        "\n",
        "\n",
        "\n",
        "    def softplus(self):\n",
        "      # softplus(x) = ln(1 + e^x)\n",
        "      # softplus'(x) = sigmoid(x)\n",
        "\n",
        "      softplus_val = math.log(1 + math.exp(self._value))\n",
        "      sigmoid_val = self.sigmoid()._value\n",
        "\n",
        "      result = Parameter(\n",
        "          softplus_val,\n",
        "          f\"Softplus({self._name})\",\n",
        "          (self, )\n",
        "      )\n",
        "\n",
        "      def _backward():\n",
        "        self._grad += result._grad * sigmoid_val\n",
        "\n",
        "      result._backward = _backward\n",
        "\n",
        "      return result\n",
        "\n",
        "\n",
        "    def backward(self):\n",
        "        topo_sort = []\n",
        "        visited = set()\n",
        "        def build_topo_sort(v):\n",
        "          visited.add(v)\n",
        "          for child in v._prev:\n",
        "            build_topo_sort(child)\n",
        "          topo_sort.append(v)\n",
        "\n",
        "        build_topo_sort(self)\n",
        "\n",
        "        self._grad = 1.0\n",
        "        for node in reversed(topo_sort):\n",
        "          node._backward()\n",
        "\n",
        "\n",
        "\n",
        "from typing import List\n",
        "\n",
        "def gd(learning_rate: float, parameters: List[Parameter]) -> None:\n",
        "  for p in parameters:\n",
        "    p._value -= learning_rate * p._grad\n",
        "    p.grad = 0.0\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backpropagation (backward) test"
      ],
      "metadata": {
        "id": "2Pi8TU9WodoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = Parameter(3.0, name='a')\n",
        "b = Parameter(2.0, name='b')\n",
        "c = Parameter(5.0, name='c')\n",
        "d = Parameter(5.0, name='d')"
      ],
      "metadata": {
        "id": "HVjEz_UaP4VH"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "print(d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPhsDfAFRfhl",
        "outputId": "77540a50-2098-4432-f866-1b45a4941fdb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter a = 3.0; dL/d[a] = 0.0\n",
            "Parameter b = 2.0; dL/d[b] = 0.0\n",
            "Parameter c = 5.0; dL/d[c] = 0.0\n",
            "Parameter d = 5.0; dL/d[d] = 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "u = a * b\n",
        "v = u + c\n",
        "L = v * d\n",
        "\n",
        "print(u)\n",
        "print(v)\n",
        "print(L)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shUmekOgR_dQ",
        "outputId": "b64f25b3-20a2-4de0-ad0b-18cb619369f8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter a * b = 6.0; dL/d[a * b] = 0.0\n",
            "Parameter [a * b + c] = 11.0; dL/d[[a * b + c]] = 0.0\n",
            "Parameter [a * b + c] * d = 55.0; dL/d[[a * b + c] * d] = 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "L.backward()\n",
        "\n",
        "print(L)\n",
        "print(v)\n",
        "print(d)\n",
        "print(u)\n",
        "print(c)\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIf-kJyqSQ-J",
        "outputId": "20a28052-7139-4c07-963e-4898d0c17c94"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter [a * b + c] * d = 55.0; dL/d[[a * b + c] * d] = 1.0\n",
            "Parameter [a * b + c] = 11.0; dL/d[[a * b + c]] = 5.0\n",
            "Parameter d = 5.0; dL/d[d] = 11.0\n",
            "Parameter a * b = 6.0; dL/d[a * b] = 5.0\n",
            "Parameter c = 5.0; dL/d[c] = 5.0\n",
            "Parameter a = 3.0; dL/d[a] = 10.0\n",
            "Parameter b = 2.0; dL/d[b] = 15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = Parameter(3.0, name = 'x1')\n",
        "x2 = Parameter(4.0, name = 'x2')\n",
        "\n",
        "w1 = Parameter(1.0, name = 'w1')\n",
        "w2 = Parameter(2.0, name = 'w2')\n",
        "\n",
        "x1w1 = x1 * w1;\n",
        "x2w2 = x2 * w2;\n",
        "xw = x1w1 + x2w2;\n",
        "out = xw.silu();\n",
        "\n",
        "print(out)\n",
        "print(xw)\n",
        "print(x1w1)\n",
        "print(x2w2)\n",
        "print(x1)\n",
        "print(w1)\n",
        "print(x2)\n",
        "print(w2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2iB9KltU7KW",
        "outputId": "08c79de7-e681-47e1-c6c9-669817f9e5a2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter SiLU([x1 * w1 + x2 * w2]) = 10.999816284359673; dL/d[SiLU([x1 * w1 + x2 * w2])] = 0.0\n",
            "Parameter [x1 * w1 + x2 * w2] = 11.0; dL/d[[x1 * w1 + x2 * w2]] = 0.0\n",
            "Parameter x1 * w1 = 3.0; dL/d[x1 * w1] = 0.0\n",
            "Parameter x2 * w2 = 8.0; dL/d[x2 * w2] = 0.0\n",
            "Parameter x1 = 3.0; dL/d[x1] = 0.0\n",
            "Parameter w1 = 1.0; dL/d[w1] = 0.0\n",
            "Parameter x2 = 4.0; dL/d[x2] = 0.0\n",
            "Parameter w2 = 2.0; dL/d[w2] = 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out.backward()\n",
        "\n",
        "print(out)\n",
        "print(xw)\n",
        "print(x1w1)\n",
        "print(x2w2)\n",
        "print(x1)\n",
        "print(w1)\n",
        "print(x2)\n",
        "print(w2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsewcXM6Zs1l",
        "outputId": "773de004-165b-483a-d526-1f39274527b4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter SiLU([x1 * w1 + x2 * w2]) = 10.999816284359673; dL/d[SiLU([x1 * w1 + x2 * w2])] = 1.0\n",
            "Parameter [x1 * w1 + x2 * w2] = 11.0; dL/d[[x1 * w1 + x2 * w2]] = 1.0001670111501668\n",
            "Parameter x1 * w1 = 3.0; dL/d[x1 * w1] = 1.0001670111501668\n",
            "Parameter x2 * w2 = 8.0; dL/d[x2 * w2] = 1.0001670111501668\n",
            "Parameter x1 = 3.0; dL/d[x1] = 1.0001670111501668\n",
            "Parameter w1 = 1.0; dL/d[w1] = 3.0005010334505005\n",
            "Parameter x2 = 4.0; dL/d[x2] = 2.0003340223003336\n",
            "Parameter w2 = 2.0; dL/d[w2] = 4.000668044600667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking gradient descent"
      ],
      "metadata": {
        "id": "wiV7BERYqoMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = Parameter(0.5, name='w')\n",
        "b = Parameter(0.1, name='b')\n",
        "x = Parameter(5.0, name='x')\n",
        "\n",
        "learning_rate = 0.0001\n",
        "y_target = Parameter(3.0, name='target')\n",
        "\n",
        "for n in range(15):\n",
        "  # forward pass\n",
        "  y_pred = (x * w + b).softplus()\n",
        "  loss = (y_pred - y_target) ** 2\n",
        "\n",
        "  # backward pass\n",
        "  loss.backward()\n",
        "\n",
        "  # update\n",
        "  gd(learning_rate, [w, b])\n",
        "\n",
        "  print(f\"loss {n} steps: \\t {loss._value}\")\n"
      ],
      "metadata": {
        "id": "zDn-9wXCjfMn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d36ce45-daac-4cc4-b8cc-5881ae96e76d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0 steps: \t 0.10781720831300634\n",
            "loss 1 steps: \t 0.106847734907399\n",
            "loss 2 steps: \t 0.10492582341195823\n",
            "loss 3 steps: \t 0.10208527320076471\n",
            "loss 4 steps: \t 0.09837610800843254\n",
            "loss 5 steps: \t 0.09386377348935533\n",
            "loss 6 steps: \t 0.08862808072992617\n",
            "loss 7 steps: \t 0.08276190756761778\n",
            "loss 8 steps: \t 0.07636967290825829\n",
            "loss 9 steps: \t 0.06956560274459106\n",
            "loss 10 steps: \t 0.062471810231867486\n",
            "loss 11 steps: \t 0.05521621590712735\n",
            "loss 12 steps: \t 0.04793033785728071\n",
            "loss 13 steps: \t 0.04074698523165677\n",
            "loss 14 steps: \t 0.03379789182232777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred)\n",
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-m6MSGGnRs1",
        "outputId": "7a14f692-771c-4fe2-95d8-d03720b3aa48"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter Softplus([x * w + b]) = 2.816157970468318; dL/d[Softplus([x * w + b])] = -0.36768405906336366\n",
            "Parameter w = 0.5335636450314861; dL/d[w] = -38.60247457492748\n",
            "Parameter b = 0.10671272900629727; dL/d[b] = -7.720494914985498\n"
          ]
        }
      ]
    }
  ]
}
