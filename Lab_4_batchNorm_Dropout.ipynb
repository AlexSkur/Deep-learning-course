{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load_digits() dataset from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "print(digits.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n",
      "1797\n"
     ]
    }
   ],
   "source": [
    "print(digits.data)\n",
    "print(len(digits.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 ... 8 9 8]\n",
      "1797\n"
     ]
    }
   ],
   "source": [
    "print(digits.target)\n",
    "print(len(digits.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gray()\n",
    "plt.matshow(digits.images[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP class with option to use Dropout and Batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers_count, layers_sizes, activations, dropout_in_layers=None, batchNorm=None):\n",
    "        # dropout_in_layer = [p1, p2, p3, ...]\n",
    "        # batchNorm = [True, False, True, ...]\n",
    "\n",
    "        super().__init__()\n",
    "        self.layers_count = layers_count\n",
    "        self.layers_sizes = layers_sizes\n",
    "        self.activations = activations\n",
    "        self.dropout_in_layers = dropout_in_layers\n",
    "        self.batchNorm = batchNorm\n",
    "        self.layers = torch.nn.Sequential()\n",
    "\n",
    "        for i in range(self.layers_count - 1):\n",
    "            layer = torch.nn.Linear(in_features=self.layers_sizes[i], out_features=self.layers_sizes[i+1])\n",
    "            self.layers.append(layer)\n",
    "            self.layers.append(self.activations[i])\n",
    "            if (self.batchNorm):\n",
    "                if (self.batchNorm[i]):\n",
    "                    self.layers.append(torch.nn.BatchNorm1d(self.layers_sizes[i+1]))\n",
    "            if (self.dropout_in_layers):\n",
    "                if (self.dropout_in_layers[i]):\n",
    "                    torch.nn.Dropout(p=dropout_in_layers[i])\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitsDataset(Dataset):\n",
    "    def __init__(self, X, labels):\n",
    "        # convert into Pytorch tensors\n",
    "        self.X = torch.from_numpy(X).to(dtype=torch.float32)\n",
    "        self.labels = torch.from_numpy(labels).to(dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # return super().__getitem__(index)\n",
    "        return (self.X[index], self.labels[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n",
      "[0 1 2 ... 8 9 8]\n"
     ]
    }
   ],
   "source": [
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing MLP class using load_digits() dataset from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "digits_data_training = DigitsDataset(X_train, y_train)\n",
    "digits_data_testing = DigitsDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(digits_data_testing, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(digits_data_testing, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP with Dropout and BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initializing\n",
    "mlp = MLP(\n",
    "    4, \n",
    "    [64, 32, 16, 10], \n",
    "    [torch.nn.ReLU(), torch.nn.ReLU(), torch.nn.Softmax(dim=1)],\n",
    "    dropout_in_layers=[0.2, 0.2, None],\n",
    "    batchNorm=[True, True, True] \n",
    ")\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Epoch 1\n",
      "Epoch 1 - Training loss: 2.1651563274449317\n",
      "\n",
      "Starting Epoch 2\n",
      "Epoch 2 - Training loss: 1.3899903955130741\n",
      "\n",
      "Starting Epoch 3\n",
      "Epoch 3 - Training loss: 1.1282913191565151\n",
      "\n",
      "Starting Epoch 4\n",
      "Epoch 4 - Training loss: 0.9460794925689697\n",
      "\n",
      "Starting Epoch 5\n",
      "Epoch 5 - Training loss: 0.905709577017817\n",
      "\n",
      "Starting Epoch 6\n",
      "Epoch 6 - Training loss: 0.893536541996331\n",
      "\n",
      "Starting Epoch 7\n",
      "Epoch 7 - Training loss: 0.8000829302031418\n",
      "\n",
      "Starting Epoch 8\n",
      "Epoch 8 - Training loss: 0.8066649683590593\n",
      "\n",
      "Starting Epoch 9\n",
      "Epoch 9 - Training loss: 0.7367044985294342\n",
      "\n",
      "Starting Epoch 10\n",
      "Epoch 10 - Training loss: 0.6886012173932174\n",
      "\n",
      "Starting Epoch 11\n",
      "Epoch 11 - Training loss: 0.729349267893824\n",
      "\n",
      "Starting Epoch 12\n",
      "Epoch 12 - Training loss: 0.6376977994524199\n",
      "\n",
      "Starting Epoch 13\n",
      "Epoch 13 - Training loss: 0.6471770272172731\n",
      "\n",
      "Starting Epoch 14\n",
      "Epoch 14 - Training loss: 0.6931796063636911\n",
      "\n",
      "Starting Epoch 15\n",
      "Epoch 15 - Training loss: 0.644521578632552\n",
      "\n",
      "Starting Epoch 16\n",
      "Epoch 16 - Training loss: 0.672138931422398\n",
      "\n",
      "Starting Epoch 17\n",
      "Epoch 17 - Training loss: 0.5989454645535042\n",
      "\n",
      "Starting Epoch 18\n",
      "Epoch 18 - Training loss: 0.558727719660463\n",
      "\n",
      "Starting Epoch 19\n",
      "Epoch 19 - Training loss: 0.6060957240647283\n",
      "\n",
      "Starting Epoch 20\n",
      "Epoch 20 - Training loss: 0.639476051618313\n",
      "\n",
      "Starting Epoch 21\n",
      "Epoch 21 - Training loss: 0.559924773101149\n",
      "\n",
      "Starting Epoch 22\n",
      "Epoch 22 - Training loss: 0.6444431420030265\n",
      "\n",
      "Starting Epoch 23\n",
      "Epoch 23 - Training loss: 0.5709795736033341\n",
      "\n",
      "Starting Epoch 24\n",
      "Epoch 24 - Training loss: 0.5749188368690425\n",
      "\n",
      "Starting Epoch 25\n",
      "Epoch 25 - Training loss: 0.5226746016535265\n",
      "\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "n = len(train_loader)\n",
    "\n",
    "# Train loop\n",
    "for epoch in range(0, 25):\n",
    "    print(f'\\nStarting Epoch {epoch + 1}')\n",
    "\n",
    "    current_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = mlp(images)\n",
    "        loss = loss_function(outputs, labels.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()  # update the values\n",
    "\n",
    "        current_loss += loss.item()\n",
    "\n",
    "    loss_after_epoch = current_loss / n\n",
    "    print(f\"Epoch {epoch + 1} - Training loss: {loss_after_epoch}\")\n",
    "\n",
    "print(\"\\nTraining has completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
